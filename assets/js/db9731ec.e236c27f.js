"use strict";(self.webpackChunksrc=self.webpackChunksrc||[]).push([[782],{7185:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>d,toc:()=>c});var i=n(4848),r=n(8453);const o={title:"IStereoDepth"},s="IStereoDepth",d={id:"Modules/IStereoDepth",title:"IStereoDepth",description:"Estimate dense depth map of a pair of rectified and undistorted stereo image.",source:"@site/docs/02-Modules/02-IStereoDepth.md",sourceDirName:"02-Modules",slug:"/Modules/IStereoDepth",permalink:"/wiki/Modules/IStereoDepth",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"IStereoDepth"},sidebar:"tutorialSidebar",previous:{title:"IMatcher",permalink:"/wiki/Modules/IMatcher"},next:{title:"IFrontend",permalink:"/wiki/Modules/IFrontend"}},l={},c=[{value:"Interface",id:"interface",level:2},{value:"Methods to Implement",id:"methods-to-implement",level:3},{value:"Implementations",id:"implementations",level:2},{value:"Modifiers",id:"modifiers",level:2}];function a(e){const t={admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"istereodepth",children:"IStereoDepth"})}),"\n",(0,i.jsx)(t.p,{children:"Estimate dense depth map of a pair of rectified and undistorted stereo image."}),"\n",(0,i.jsx)(t.h2,{id:"interface",children:"Interface"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'title="Module/Frontend/StereoDepth.py"',children:"class IStereoDepth(ABC, Generic[T_Context], ConfigTestableSubclass):\r\n    @property\r\n    @abstractmethod\r\n    def provide_cov(self) -> bool: ...\r\n    \r\n    @abstractmethod\r\n    def init_context(self) -> T_Context: ...\r\n    \r\n    @abstractmethod\r\n    def estimate(self, frame: SourceDataFrame) -> tuple[torch.Tensor, torch.Tensor | None]: ...\n"})}),"\n",(0,i.jsx)(t.h3,{id:"methods-to-implement",children:"Methods to Implement"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"IStereoDepth.estimate(frame: SourceDataFrame) -> depth, depth_cov"})}),"\n",(0,i.jsxs)(t.p,{children:["Given a frame with imageL, imageR being Bx3xHxW, return ",(0,i.jsx)(t.code,{children:"output"})," where"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["depth         - Bx1xHxW shaped torch.Tensor, estimated depth map\r\nmaybe padded with ",(0,i.jsx)(t.code,{children:"nan"})," if model can't output prediction with same shape as input image."]}),"\n",(0,i.jsxs)(t.li,{children:["depth_cov     - Bx1xHxW shaped torch.Tensor or None, estimated covariance of depth map (if provided)\r\nmaybe padded with ",(0,i.jsx)(t.code,{children:"nan"})," if model can't output prediction with same shape as input image."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"IStereoDepth.provide_cov"})}),"\n",(0,i.jsxs)(t.p,{children:["Implement this property (to simply return ",(0,i.jsx)(t.code,{children:"True"})," or ",(0,i.jsx)(t.code,{children:"False"}),") to indicate whether the depth estimation network will jointly estimate the covariance / uncertainty."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"IStereoDepth.init_context(self) -> T_Context"})}),"\n",(0,i.jsxs)(t.p,{children:["Works similar to the ",(0,i.jsx)(t.code,{children:"__init__"})," method in python, where all used properties are stored in a dictionary and stored at ",(0,i.jsx)(t.code,{children:"self.context"}),". This is for better static type inference on the property of each implementation of ",(0,i.jsx)(t.code,{children:"IStereoDepth"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["In this method you can access the configuration passed on initialization by ",(0,i.jsx)(t.code,{children:"self.config"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"implementations",children:"Implementations"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class GTDepth(IStereoDepth[None])"})}),"\n",(0,i.jsxs)(t.p,{children:["Read ground truth depth from dataset (input ",(0,i.jsx)(t.code,{children:"SourceDataFrame"}),"). Will raise exception if dataset does not provide ",(0,i.jsx)(t.code,{children:"gtDepth"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class FlowFormerDepth(IStereoDepth[ModelContext])"})}),"\n",(0,i.jsxs)(t.p,{children:["Estimate disparity using the vanilla ",(0,i.jsx)(t.code,{children:"FlowFormer"})," model. Then derive depth using ",(0,i.jsx)(t.code,{children:"depth = (baseline * fx) / disparity"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class FlowFormerCovDepth(IStereoDepth[ModelContext])"})}),"\n",(0,i.jsx)(t.p,{children:"Jointly estimate disparity and disparity uncertainty, then derive deptha and corresponding depth uncertainty using formula above and the derived first-order taylor approximation in Appendix."}),"\n",(0,i.jsx)(t.admonition,{type:"info",children:(0,i.jsxs)(t.p,{children:["This is ",(0,i.jsx)(t.em,{children:"not"})," the model used in MAC-VO. Instead, we used an implementation to ",(0,i.jsx)(t.code,{children:"IFrontend"})," interface to jointly estimate\r\nflow and disparity (thus depth) for efficiency. See page for ",(0,i.jsx)(t.code,{children:"IFrontend"})," interface for detail."]})}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class TartanVODepth(IStereoDepth[ModelContext])"})}),"\n",(0,i.jsx)(t.p,{children:"Estimate dense disparity map using TartanVO network, then convert to depth."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class UniMatchStereoDepth(IStereoDepth[ModelContext])"})}),"\n",(0,i.jsx)(t.admonition,{type:"warning",children:(0,i.jsx)(t.p,{children:"Will be released soon."})}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class UniMatchCovDepth(IStereoDepth[ModelContext])"})}),"\n",(0,i.jsx)(t.admonition,{type:"warning",children:(0,i.jsx)(t.p,{children:"Will be released soon."})}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class ApplyGTCov(IStereoDepth[IStereoDepth])"})}),"\n",(0,i.jsx)(t.admonition,{type:"warning",children:(0,i.jsx)(t.p,{children:"Will be released soon."})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"modifiers",children:"Modifiers"}),"\n",(0,i.jsxs)(t.p,{children:['Modifiers are "higher-order module" that creates a new ',(0,i.jsx)(t.code,{children:"IStereoDepth"})," by tweaking the input/output of some designated ",(0,i.jsx)(t.code,{children:"IStereoDepth"})," implementation."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.code,{children:"class ApplyGTCov(IStereoDepth[IStereoDepth])"})}),"\n",(0,i.jsxs)(t.p,{children:["A higher-order-module that encapsulates a ",(0,i.jsx)(t.code,{children:"IStereoDepth"})," module."]}),"\n",(0,i.jsxs)(t.p,{children:["Always compare the estimated output of encapsulated ",(0,i.jsx)(t.code,{children:"IStereoDepth"})," with ground truth matching and convert\r\nerror in estimation to 'estimated' covariance."]}),"\n",(0,i.jsxs)(t.p,{children:["Will raise ",(0,i.jsx)(t.code,{children:"AssertionError"})," if frame does not have gtDepth."]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>d});var i=n(6540);const r={},o=i.createContext(r);function s(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);